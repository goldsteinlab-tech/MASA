---
title: "Motif-Associated Signs of Activity (MASA)"
author: "Leslie Cohen"
output: 
  rmarkdown::html_vignette:
    css: style.css
vignette: >
  %\VignetteIndexEntry{Motif-Associated Signs of Activity (MASA)}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

Motif-Associated Signs of Activity (MASA)  is a computational tool designed to predict which transcription factors (TFs) change their activity between two experimental conditions using ATAC-seq data. MASA is intended for biologists and bioinformaticians interested in chromatin accessibility and transcriptional regulation.

## Introduction

## Input:

- BAM files (aligned ATAC-seq reads)

- MACS2 output peak files (in BED or narrowPeak format)

## Core Functions:

MASA integrates differential accessibility, motif enrichment, and footprinting analysis to infer transcription factor activity changes between two conditions.

Differential accessible regions and motif enrichment:
MASA identifies deferentially accessible peaks using HOMER and performs motif enrichment analysis on these regions. Enriched motifs are incorporated into the result files.

Footprinting and accessibility quantification.
MASA calculates flanking accessibility and transcription factor footprinting metrics from ATAC-seq BAM files, comparing them between the two conditions to detect differential TF activity.

Differential activity scores and visualization
Differential scores quantify the change in TF activity between conditions. Results are compiled into a summary table including differential activity values, and statistical significance.
MASA also provides a bagplot visualization summarizing differential footprint depth, flanking accessibility, where HOMER-enriched motifs are highlighted.


## How Does MASA Work?

## Data Processing:

Reads BAM files and identifies accessible chromatin regions using MACS2 peak files.

Calculates chromatin accessibility and TF footprints for each condition.

Computes the difference (delta) in accessibility and footprinting for each TF motif between the two conditions.

Performs HOMER motif enrichment analysis on differentially-accessible regions. 

## Output Generation:

Produces a results table with TF scores, p-values, and other relevant statistics.

Generates a plot for visualizing the distribution and outliers among TF activity changes.

## MASA Project Environment: Requirements and Structure
Before running MASA, you must organize your project files in a specific way to ensure smooth operation and reproducibility. Here’s a detailed guide on setting up your environment.

## 1. Required Directories
You need to prepare two main directories for each project:

### a. Merged BAM Directory
Contains one merged, sorted, and indexed BAM file containing all replicas per condition (e.g., treated, control).

Each BAM file should be accompanied by:

Its index file (.bai)

A SAMtools stats file (output from samtools idxstats file.bam | tr '\t' ',' > file.csv
), named exactly like the BAM file but with a .csv extension.

### b. MACS2 Peaks Directory
Contains the MACS2 output files for each condition.

Files must be in BED or narrowPeak format.

Each file should represent the ATAC-seq peaks for a given condition.

## 2. Additional Requirements (for HOMER Integration)
If you plan to use the HOMER function (highly recommended for advanced analyses):

You must also provide individual BAM files for each replicate within each condition.

These BAM files should:

Be sorted and indexed.

Ideally, follow a consistent naming scheme:
For example, if your merged BAM is control_suffix.bam, the replicates should be named control_1.bam, control_2.bam, etc.

## 3. Project Definition File
Each project should have a project definition file (often named environment.yaml or similar), specifying:

Project name

Path to merged BAM directory

Path to MACS2 peaks directory

Reference genome version (e.g., mm10, hg38)

Treatments (all_set):
List of all conditions (e.g., treated, control)

Couples:
Define the pairs of conditions you want to compare (for use in MASA)

## Important: How to Define "couples" in Your Project File
In the couples section, always list the control condition first, followed by a hyphen (-), then the experimental condition (e.g., control-treated).

Do NOT use underscores (_)!

## Pre-processing

## Initial Processing and File Generation
This section describes the preprocessing steps required for each condition before downstream analysis. 

## ATAC-seq signal normalization
### Observed vs. Expected Table:
Using the BAM files from ATAC-seq experiments, MASA calculates the observed frequency of each 6-mer at Tn5 insertion sites. It then compares these observed counts to the expected frequencies derived from a genome-wide 6-mer library, generating an observed/expected (O/E) ratio for each 6-mer.

### Bias Factor Application:
The O/E ratios serve as bias correction factors to derive expected count per position; observed counts are normalized by these expected counts. MASA applies these factors to adjust the raw ATAC-seq signal, normalizing for sequence bias before any downstream analysis (such as accessibility, footprinting, and delta calculation).


### Step-by-Step Workflow

#### 1. Generate Nucleotide Code Files (Per Chromosome)

For each chromosome in the reference genome (mm9, mm10, hg19, hg38), MASA generates nucleotide code files (nuccode files) that encode the hexamer (6-mer) sequence at each genomic position. These files serve as a lookup table, allowing the pipeline to quickly identify the sequence context at any position during bias correction and footprinting analysis.

This pre-processing step is performed once per genome and is reused across all samples and conditions, ensuring efficient and consistent sequence bias correction throughout the analysis.

#### 2. Generate BedGraph Files

Create a BedGraph file for each condition, representing the genome-wide accessibility profile.

During this step, correct for Tn5 transposase offset by shifting the reads (+4 bp for the positive strand, -5 bp for the negative strand), which accurately centers the insertion sites.

Remove duplicate reads as part of this process.

#### 3. Hexamer Table Construction

For each condition, MASA builds a hexamer (6-mer) bias table that quantifies sequence-dependent Tn5 cutting preferences.

Using the nuccode files, MASA assigns to each genomic position the local hexamer sequence. The corresponding BedGraph file provides the number of Tn5 cuts at each position (after strand-specific Tn5 offset correction and duplicate removal). For every hexamer, MASA then:

- counts how many times it appears in the genome
(GenomicPositionCount), and
- aggregates the observed Tn5 cuts at all positions carrying this hexamer
(ObCuts).

The ratio

          ObCutRatio = ObCuts / GenomicPositionCount
          
provides an estimate of the cleavage propensity for each hexamer.

The hexamer bias table also includes additional normalization metrics, such as:

- the genomic proportion of each hexamer among all 6-mers (GPRatio), and
- a correction factor derived from these quantities.

This correction factor is used in downstream steps to rescale cut counts and remove intrinsic Tn5 sequence bias, ensuring that the resulting footprinting signal reflects true chromatin protection rather than enzymatic preference.

One hexamer bias table is generated per condition. For differential footprinting between two conditions (a couple), MASA later merges the per-condition tables into a combined hexamer file (see summary table), so that both conditions are normalized using the same hexamer set and bias estimates.


### Output files
```{r, echo=FALSE}
knitr::kable(
  data.frame(
    Step = c("Preprocessing", "Hexamer", "Peaks"),
    Output_File = c("BedGraph", "nuccode + Hexamer table", "peaks reformatted as CSV"),
    Description = c("Genome-wide Accessibility profile", "hexamer genome index + hexamer bias / frequency table", "peaks in standardized CSV format")
  )
)
```
  
  When comparing two conditions (e.g., control vs treatment), MASA generates additional files that combine information from both samples. These “couple-level” outputs ensure that footprinting and accessibility differences are evaluated on a unified genomic reference.


Summary Table:
```{r, echo=FALSE}

 knitr::kable(
  data.frame(
    Step = c(
      "Generate nuccode files ** (once per genome)",
      "Generate BedGraph (incl. Tn5 offset correction)",
      "Build hexamer table",
      "Peak reformatting"
    ),
    `Output (per condition)` = c(
      "Nuccode* files (hexamer index in the genome, shared by all conditions)",
      "BedGraph file (shifted)",
      "Hexamer bias file",
      "Hotspot table (MACS2 peaks reformatted to MASA format; one row per peak with placeholder footprint metrics)"
    ),
    `Output (per Couple)` = c(
      "",
      "",
      "Combined hexamer (merge hexamer tables for both conditions)",
      "Combined peaks / pooled hotspot  (merged hotspot table defining a common  peaks universe for both conditions)"
    )
  ),
  align = "lcc",
  caption = "Summary Table"
)


```

 
## Running the script

Your script should be in the directory bg_dir.

```{r, eval=FALSE}

library(masa)
library(hash)
library(data.table)
library(Cairo)
library(aplpack)
library(stringr)
library(dplyr)
library(ggplot2)
library(plotly)

```


```{r,include=FALSE,eval=FALSE}
numcores <- 2     # No. of CPU cores to be used
options("masa.mc.cores"=numcores)
options("masa.mc.cores.motif"=numcores)
options("masa.debug"=T)

project<-"urf"

# the names of the folders must be as below
bg_dir <-paste0("/home/leslieco/bg_files_fed_fasted/")

macs2_dir <- paste0("/home/leslieco/",project,"/macs2/")

bam_dir <- paste0("/home/leslieco/",project,"/bam_merged/")

# mm10_files directory should be downloaded and copied in the masa directory
mm_files_dir <- "/home/leslieco/mm10_files/"

mm<-"mm10"
genome <- "mm10"


#⚠️ in couples: CONTROL is the FIRST, followed by - (not underscore) flowed by the second

if (project=="urf"){
  all_set<- c("fed","fasted")
  couples<- c("fed-fasted") # the control here is fed
}

knitr::opts_knit$set(root.dir = bg_dir)
```

In the section outline below, we remove reads that align multiple times in the genome for each condition. This process is performed separately for each chromosome.

For each condition:

- A BedGraph file is created.

- Tn5 offset is corrected by shifting the reads in the BedGraph.

- A hexamer table is generated.


This step will produce:

A) Per treatment/condition (one set per sample):

- BedGraph: Genome-wide accessibility profile file (Tn5-shifted).

- Hexamer file and the corresponding nuccode* files.

- Peak file reformatted to a standardized CSV table.


B) Pair of conditions (couple):

- Combined peaks: Merged peak regions defining a shared peak universe for both conditions.

- Combined hexamer: Merged hexamer bias tables used for comparative analysis between conditions.


```{r, eval=FALSE}
setwd(bg_dir)


for (treat in all_set) {
  # Build BAM file path
  bamfile <- file.path(bam_dir, paste0(treat, ".sorted.bam"))
  
  # Count the number of cuts in the BAM file
  cc <- countReadsBAM(bamfile, mm)
  print(paste("treat:", treat, "cc:", cc))
  assign(paste0("cc_", treat), cc)
  
  # Generate a BedGraph file with cleavage counts
   cutcountfile = makeCutCountBAMWithName(bamfile, 
                                         name =  basenameWithoutExt(bamfile),
                                         refgenome=mm) 
  
  # Tn5 insertion bias correction
   hex_file <- file.path(bg_dir, paste0("Hexamer_", treat, "_", mm, ".txt"))
message("Checking Hexamer file: ", hex_file)
message("Exists? ", file.exists(hex_file))
   if (!file.exists(hex_file)) {
    message("Creating Hexamer table (and possibly nuccode) for ", treat, " ...")
     
  tab = MakeBiasCorrectionTableBAM(
  bamfile=bamfile,
  outfile=paste0("Hexamer_",treat,"_mm10.txt"),
  refgenome="mm10",
  np=6,
  atac=T   )  # Set TRUE for ATAC data. The default value is FALSE
  
   } else {
    message("Hexamer file already exists for ", treat, " -> skipping bias table generation.")
   }
   
   
  # Read MACS2 peaks and convert to CSV
  macs <- read.csv(file.path(macs2_dir, paste0(treat, "_peaks.narrowPeak")),
                   sep = "\t", header = FALSE, stringsAsFactors = FALSE)
  names(macs)[1:3] <- c('chr', 'st', 'ed')
  nr <- nrow(macs)
  
  # Create a hotspot data frame for each peak
  hotspot <- data.frame(
    ID = 1:nr, chrom. = macs$chr, start = macs$st + 1, end = macs$ed,
    MaxD = rep(0, nr),
    AveD = rep(0, nr),
    Zscore = rep(0, nr),
    pvalue = rep(0, nr)
  )
  
  # Write the hotspot table to CSV
  write.table(hotspot, file = file.path(bg_dir, paste0(treat, "_peaks.csv")), sep = ",", row.names = FALSE)
}

# Remove temporary files
temp <- list.files(bg_dir,
                   pattern = glob2rx("temp*.dat"),
                   recursive = TRUE,
                   full.names = TRUE)
file.remove(temp)

# Merge files for MASA run
for (c in couples) {
  print(c)
  set1 <- strsplit(c, "-", fixed = TRUE)[[1]][1]
  set2 <- strsplit(c, "-", fixed = TRUE)[[1]][2]
  
  # Combine hotspots for the two conditions
  assign(
    paste0(set1, "_", set2, "_peaks"),
    combineTwoHotspots(
      file.path(bg_dir, paste0(set1, "_peaks.csv")),
      file.path(bg_dir, paste0(set2, "_peaks.csv")),
      set1, set2
    )
  )
  
  # Read and clean pooled hotspot file
  pooled_path <- file.path(bg_dir, paste0("pooled_", set1, "_", set2, "_hotspot.csv"))
  pooled <- read.csv(pooled_path)
  if ("ID.1" %in% colnames(pooled)) {
    pooled <- pooled %>%
      dplyr::select(-ID.1)
    write.csv(pooled, pooled_path, row.names = FALSE)
  }
  
  # Merge the hexamer frequency tables for the two conditions
  assign(
    paste0("Hexamer_", set1, "_", set2),
    merge_two_frequency_tables(
      file.path(bg_dir, paste0("Hexamer_", set1, "_", mm, ".txt")),
      file.path(bg_dir, paste0("Hexamer_", set2, "_", mm, ".txt")),
      file.path(bg_dir, paste0("Hexamer_", set1, "_", set2, "_merged.csv"))
    )
  )
}


```

## HOMER : Differential ATAC-seq analysis & motif enrichment
  
## Run HOMER

To use this part of the workflow with MASA, it is essential to have HOMER installed on your system, following the official recommendations provided on the HOMER installation page:

http://homer.ucsd.edu/homer/introduction/install.htm

Please make sure to carefully follow the instructions on the official HOMER website to ensure a correct installation and full access to all required features.

With MASA, it is highly recommended to run HOMER to perform motif analysis on deferentially accessible ATAC-seq peaks. 

Integrating HOMER allows you to identify transcription factor motifs that are enriched in regions showing differential accessibility between conditions.

In this chunk, the workflow proceeds as follows:
  
  - Load the peak files and all BAM files for each replicate within every condition.

- Use HOMER to count the number of tags per peak for each replicate.

- Normalize these counts across replicates and conditions.

- Perform differential analysis with DESeq2 via HOMER, generating an annotated file of differentially accessible peaks.

- For these differential peaks, run motif enrichment analysis with HOMER.

The results of the motif enrichment analysis are displayed as gold rings in MASA’s final plot (pdf zoom in, pdf zoom out, jpg, svg, html). In addition, motif enrichment p value threshold for each motif appears and in the MASA output table.


  http://homer.ucsd.edu/homer/introduction/install.html


```{r, echo=TRUE, message=FALSE, warning=FALSE ,results = 'hide',eval=FALSE}


# ============================
# SETTINGS
# ============================

# Path to the HOMER binary directory
homer_bin <- "/home/leslieco/software/homer/bin/"

# Directory containing all BAM files (replicates)
work_dir <- bam_dir

# Peak file merged from previous MASA steps
merged_peak <- file.path(bg_dir, "pooled_fasted_fed_hotspot_modify.txt")

# Directory for HOMER output
output_dir <- file.path(bg_dir, paste0("homer_res_", project))

# Output file for annotatePeak.pl
annotate_outfile <- file.path(bg_dir, "fasted_annot.txt")

# Output file for getDiffExpression.pl
diffexp_outfile <- file.path(bg_dir, "fasted_output.txt")

# Reference genome (e.g., mm10, hg38)
genome <- "mm10"

# Replicate groups for getDiffExpression.pl (adapt as needed)
group1 <- c("fed", "fed", "fed") # 3 replicas 
group2 <- c("fasted", "fasted", "fasted") # 3 replicas 

# Reformat the merged peak file for HOMER
input_file1 <- file.path(bg_dir, "pooled_fasted_hotspot.csv")
output_file1 <- file.path(bg_dir, "pooled_fasted_hotspot_modify.txt")

process_hotspot_file(
  input_file1,
  output_file1
)

library("DESeq2")

# 1. Create tag directories for each BAM file (replicate)
# This will create tag directories in the merged BAM directory
# BAM files must be named with the pattern "_[0-9].bam"
# Can take more than 30 min

# PATH expected for the Tag Directories

bam_files_all <- list.files(work_dir, pattern = "\\.bam$", full.names = TRUE)
bam_files <- bam_files_all[grepl("[0-9]\\.bam$", bam_files_all)]
td_paths <-  file.path(work_dir, paste0("TD_", sub("\\.bam$", "", basename(bam_files))))

# Check of TDs
if (all(dir.exists(td_paths))) {
  message("All Tag Directories already exist, skipping creation.")
  td_dirs <- td_paths
} else {
  td_dirs <- create_tag_directories(
  homer_bin ,
  work_dir ,
  condition_order = c("fed", "fasted"),  # control first, treatment second !!!
  verbose = TRUE
)
}


# 2. Peak annotation using HOMER
# This will generate an annotation file in bg_dir
run_annotate_peak(
  homer_bin,
  work_dir,
  output_file1,
  genome,
  td_dirs,
  annotate_outfile
)

# 3. Differential analysis with HOMER
# This will generate a diff expression file in bg_dir
run_diff_expression(
  homer_bin,
  work_dir,
  annotate_outfile,
  diffexp_outfile,
  group1,
  group2
)

# 4. Create a file with only differential peaks (BED format and table with l2fc, padj, pval) in work_dir(bam_merged)

diffexp_outfile1<-"fasted_output.txt"

create_diff_peak_files(
  input_path = bg_dir,
  input_filename = diffexp_outfile1,
  sep = "\t",
  chr = "Chr",
  start = "Start",
  end = "End",
  padj_cutoff = 0.05, # adjust as needed
  l2fc_cutoff = 0.5,    # adjust as needed
  output_prefix = "my_peaks"
)

# copy the BED file (not usually necessary in R, but shown for completeness) to bg_dir
file.copy(
  from = file.path(work_dir, "my_peaks_simple.bed"),
  to = file.path(bg_dir, "my_peaks_simple.bed"),
  overwrite = TRUE
)

# 5. Run HOMER motif enrichment
input_bed <- file.path(bg_dir, "my_peaks_simple.bed")
output_folder <- file.path(bg_dir, "homer_motif_res")
genome_build <- "mm10"
homer_exe <- file.path(homer_bin, "findMotifsGenome.pl")

MASA_DIR <- "/home/leslieco/masa/"  # <-- User edits this line for their install
motif_file <- file.path(MASA_DIR, "/inst/data/all_cluster_motifs.motifs")

extra_args1 <- paste0("-mknown ", motif_file)

# homer enrichment , can take more than 30min
run_homer(
  input_bed,
  output_folder,
  genome_build,
  homer_exe,
  extra_args1
)

```

## MASA Processing: Footprinting and TF Activity Inference

In the final step, MASA integrates all precomputed inputs to quantify transcription factor (TF) activity differences between conditions. For each condition pair, MASA performs sequence-bias–corrected footprinting over all genomic motif occurrences and summarizes the results using a bagplot.

### Input objects
For each condition, a `CutCount` object is created from the ATAC-seq BedGraph file (`*_AC_cutcount.bgr.gz`).

These objects store Tn5-shifted cut profiles and are used as the control and treatment signals in the footprinting & flanking accessibility analysis.

In addition, MASA loads:

- MotifDB : archetype motif occurrence coordinates derived from a FIMO genome-wide scan. 
These files (mm10_files_v1.0.tar.gz, hg19_files_v1.0.tar.gz) are available here: https://doi.org/10.5281/zenodo.18182843

- Merged hexamer bias table (`Hexamer_set1_set2_merged.csv`): used for sequence-bias correction. 

- **Pooled hotspot file** (`pooled_set1_set2_hotspot.csv`): merged peak regions defining the common universe of sites where footprint are calculated.

### Running MASA by motif batches
For each couple of conditions (e.g., `fed` vs `fasted`), MASA constructs a `GFootOption` object specifying:

- the merged hexamer bias file, and  

- the hexamer index pattern (`nuccode{genome}6mer{chr}.dat`).

The nuccode files were generated for mm10 (mm10_nuccode_v1.0.tar.gz) and hg19 (hg19_nuccode_v1.0.tar.gz), and available here: https://doi.org/10.5281/zenodo.18182843

The main footprinting routine is performed with the `GFoot()` function:

- `control` and `treatment` correspond to the two `CutCount` objects,  

- `sitefile` points to the pooled hotspot file (merged peaks),  

- `motifDB` provides genomic coordinates of archetype motif occurrences, 

- `gfootoption` controls bias correction and hexamer handling,  

- `outputdir` and `cachedir` store intermediate and final results.


To make the computation efficient, motifs are processed in **batches of 25**.  
The script automatically detects any existing `*_footprint_depth_table.csv` files and resumes from the next motif index if a previous run was interrupted. This restart mechanism is driven by the `start_motif` variable.


The `run()` function applies GFoot to all motifs in the specified range, using:


- `mc.cores` to parallelize over CPU cores,  

- `graphout = TRUE` to generate footprint plots,  

- `yrange` to harmonize the y-axis scale across motifs.

### Flanking and central accessibility
For each motif occurrence, MASA quantifies:

- central accessibility: Tn5 cuts over the motif core, where a footprint may appear, and

- flanking accessibility: Tn5 cuts in the surrounding regions, providing a local background reference.

These signals are integrated into three likelihood-ratio statistics:

- lrmotif — accessibility change at the motif center,

- lrflanking — accessibility change in the surrounding regions,

- lrtotal — combined statistic (motif + flanks), used to assess TF activity shifts.

This flanking-versus-center framework ensures that footprint depth reflects true binding-dependent protection rather than broader chromatin accessibility changes.

### Merging footprint tables
Each batch produces a separate `*_footprint_depth_table.csv` file. 

After all batches are completed, these files are concatenated into a single merged table:

- `*_hotspot_footprint_depth_table_merged.csv`

This table contains, for each motif:

- footprint depths in control and treatment (`fdepth1`, `fdepth2`),  

- mean cut counts (`meancc1`, `meancc2`),  

- likelihood-ratio statistics derived from central and flanking accessibility (`lrmotif`, `lrflanking`, `lrtotal`),  

- the number of motif sites used (`numsite`).

### Visualization and integration with HOMER

To summarize TF activity changes, MASA calls `gen_bagplot_masa()` function.
This step:

- generates a **plot**, where each point corresponds to a motif/TF, 

- highlights motifs with significant differential footprinting (based on q-values),  

- optionally annotates motifs using HOMER motif enrichment results based on archetype motifs (`knownResults.txt`), allowing the user to cross-reference footprint-based activity changes with motif enrichment p-values.

Both **PDF** and **HTML** reports are generated, providing an interactive overview of TFs that gain or lose activity between the two conditions.

Finally, `sessionInfo()` is printed to record the R environment and package versions used in the analysis, ensuring full reproducibility of the MASA run.


```{r, echo=TRUE,message=FALSE, warning=FALSE,results='hide', fig.show='hide',eval=FALSE}

# Set working directory to bg_dir

knitr::opts_knit$set(root.dir = "/home/leslieco/bg_files_fed_fasted/")

# Load libraries 

library(masa)
library(dplyr,tidyr)
library(stringr)
library(ggplot2)
library(ggExtra)
library(plotly)

# Base directories 

bg_dir <- "/home/leslieco/bg_files_fed_fasted/"
mm_files_dir <- "/home/leslieco/mm10_files/"
mm <- "mm10"

# Analysis parameters 

numcores <- 2
motif_no <- 577 # total number of motifs in motifDB. This number should not be changed


# Treatments and couples 

all_set <- c("fed", "fasted")
couples <- c("fed-fasted")

# HOMER motif results 

homer_results_file <- file.path(bg_dir, "homer_motif_res", "knownResults.txt")

# Load motif database (FIMO-based archetype motif scan results) 

motifdb_mm <- MotifDB(
motiflistfile = file.path(mm_files_dir, paste0("motiflist_", mm, "_cluster.txt")),
directory = file.path(mm_files_dir, paste0(mm, "_cluster_fimo"))
)

# Initialize CutCount object from BedGraph files 
# Each CutCount object stores ATAC-seq cut profiles for a given condition

for (treat in all_set) {
  assign(
  treat,
  CutCount(
  file = file.path(bg_dir, paste0(treat, "_AC_cutcount.bgr.gz")),
  count = 1,
  name = treat))
}

# Run MASA to generate footprint_depth_table files per couple 

for (c in couples) {
  message("Processing couple: ", c)

  set1 <- strsplit(c, "-", fixed = TRUE)[[1]][1] # control condition
  set2 <- strsplit(c, "-", fixed = TRUE)[[1]][2] # treatment condition

# Define bias-correction options using the merged hexamer table
  gfootoption_couple <- GFootOption(
  biasfile = file.path(bg_dir, paste0("Hexamer_", set1, "_", set2, "_merged.csv")),
  hexamer_pattern = paste0("nuccode", mm, "6mer{chr}.dat")
  )
  
  setwd(bg_dir)

# Check whether footprint_depth_table outputs already exist (In case a restart was forced)

  output_files<- list.files(bg_dir,
                            pattern= glob2rx(paste0(set1,"_",set2,"_On_pooled_",set1,"_",set2,
                                                    "_hotspot_footprint_depth_table",".csv")),
                            recursive = TRUE)
  if (length(output_files)==0) {
    start_motif<-1
  } else{
    # Resume: infer starting motif index from the last output folder name
    start_motif<-dirname(output_files) %>%  # directory name
      str_split(.,"\\_", simplify = TRUE) %>%   # separate by underscore
      as.data.frame (stringsAsFactors=F)%>%
      dplyr::select(tail(names(.), 1)) %>%  # keep only the last column
      mutate_if(is.character,as.numeric) %>%  #convert to numeric
      max+25 #Identify the last processed index and increment by 25 to start the next batch
  }

# Run MASA in batches of 25 motifs
  if (start_motif<motif_no) { 
  
    for (r in seq(start_motif, motif_no, by = 25)) {
      GFoot_obj <- GFoot(
      control = get(set1),
      treatment = get(set2),
      sitefile = paste0("pooled_",set1,"_",set2,"_hotspot.csv"),
      motifDB = motifdb_mm,
      gfootoption = gfootoption_couple,
      outputdir = file.path(bg_dir, paste0("OUTPUT_", c, "_", r)),
      cachedir = file.path(bg_dir, paste0("CACHE_", c, "_", r))
      )


    run(
      GFoot_obj,
      graphout = T,
      yrange = c(-2.2, 1.0),
      mc.cores = numcores,
      range=r:ifelse(r+24<motif_no,r+24,motif_no), 
      run_set=c
    )
    gc() #garbage collector
  }

  setwd(bg_dir)

# Merge footprint depth tables produced for all motif batches 
# (central + flanking accessibility information for all motifs)

  merge_output<-paste0("find  . -type f -name '",
                        set1,"_",set2,"_On_pooled_",set1,"_",set2,
                        "_hotspot_footprint_depth_table.csv' -exec tail -n +2 -q {} ';'",
                        ">",set1,"_",set2,"_On_pooled_",
                         set1,"_",set2,"_hotspot_footprint_depth_table_merged.csv")
  
    system(merge_output)
    
    #read the merged footprint depth table
# This table includes both central (motif) and flanking accessibility metrics

    dat= read.table(paste0(bg_dir,set1,"_",set2,"_On_pooled_",set1,"_",set2,"_hotspot_footprint_depth_table_merged.csv"), quote="\"", comment.char="") 
    
    #add column names
    colnames(dat)<-c("num","filename","center","logo","motiflength","motif","memeNo","memeEntry","lrmotif","lrflanking",
                     "lrtotal","fdepth1","fdepth2","meancc1","meancc2","numsite")
    
 # Generate MASA plots and interactive report 
# The bagplot summarizes TF activity changes based on flanking + motif-core accessibility

   test_gen<-gen_bagplot_masa(dat,
                              dataname1=set1,
                              dataname2=set2,
                              qvaluethreshold_bagplot=0.05,
                              factor=1.5,
                              pdf = TRUE,
                              html=TRUE,
                              include_homer_results = TRUE,
                              homer_results_file = homer_results_file,
                              pval_threshold_homer = 0.05)
   
     dev.off()
  }
}
```    


```{r,eval=TRUE}
# Session info for reproducibility/debugging
sessionInfo()

```
